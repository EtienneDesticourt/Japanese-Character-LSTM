{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from utils import encode, get_save_callback, build_sequence_array\n",
    "from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\\\full_text.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    full_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(np.load(\"data\\\\labels.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40\n",
    "NUM_INPUTS = len(labels)\n",
    "TEST_SPLIT_PERCENTAGE=0.2\n",
    "VAL_SPLIT_PERCENTAGE=0.1\n",
    "STRIDE = 3\n",
    "NUM_SAMPLES = 10000 # Just right 8gb of ram\n",
    "MODEL = \"M5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_id = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_id += 1\n",
    "model = build_model(MODEL, SEQUENCE_LENGTH, NUM_INPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text = full_text[2000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.3183 - acc: 0.2477Epoch 00000: saving model to weights\\LSTM_17_.00-0.248-4.317-0.271-3.989.h5\n",
      "9000/9000 [==============================] - 43s - loss: 4.3166 - acc: 0.2480 - val_loss: 3.9890 - val_acc: 0.2710\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.4811 - acc: 0.3369Epoch 00001: saving model to weights\\LSTM_17_.01-0.337-3.481-0.283-3.883.h5\n",
      "9000/9000 [==============================] - 40s - loss: 3.4809 - acc: 0.3372 - val_loss: 3.8830 - val_acc: 0.2830\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.8028 - acc: 0.4297Epoch 00002: saving model to weights\\LSTM_17_.02-0.429-2.804-0.300-3.948.h5\n",
      "9000/9000 [==============================] - 40s - loss: 2.8039 - acc: 0.4292 - val_loss: 3.9479 - val_acc: 0.3000\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.7353 - acc: 0.3206Epoch 00000: saving model to weights\\LSTM_17_.00-0.321-3.735-0.357-3.520.h5\n",
      "9000/9000 [==============================] - 45s - loss: 3.7348 - acc: 0.3207 - val_loss: 3.5195 - val_acc: 0.3570\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.0040 - acc: 0.4084Epoch 00001: saving model to weights\\LSTM_17_.01-0.408-3.007-0.359-3.454.h5\n",
      "9000/9000 [==============================] - 44s - loss: 3.0071 - acc: 0.4080 - val_loss: 3.4540 - val_acc: 0.3590\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.4235 - acc: 0.4924Epoch 00002: saving model to weights\\LSTM_17_.02-0.492-2.421-0.352-3.562.h5\n",
      "9000/9000 [==============================] - 45s - loss: 2.4210 - acc: 0.4924 - val_loss: 3.5620 - val_acc: 0.3520\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.8288 - acc: 0.2008Epoch 00000: saving model to weights\\LSTM_17_.00-0.201-4.826-0.218-4.612.h5\n",
      "9000/9000 [==============================] - 44s - loss: 4.8264 - acc: 0.2009 - val_loss: 4.6123 - val_acc: 0.2180\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.8151 - acc: 0.3022Epoch 00001: saving model to weights\\LSTM_17_.01-0.302-3.815-0.243-4.472.h5\n",
      "9000/9000 [==============================] - 43s - loss: 3.8148 - acc: 0.3024 - val_loss: 4.4724 - val_acc: 0.2430\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.0054 - acc: 0.4065Epoch 00002: saving model to weights\\LSTM_17_.02-0.407-3.006-0.272-4.503.h5\n",
      "9000/9000 [==============================] - 42s - loss: 3.0062 - acc: 0.4066 - val_loss: 4.5031 - val_acc: 0.2720\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.4783 - acc: 0.2504Epoch 00000: saving model to weights\\LSTM_17_.00-0.250-4.481-0.267-4.332.h5\n",
      "9000/9000 [==============================] - 44s - loss: 4.4813 - acc: 0.2502 - val_loss: 4.3317 - val_acc: 0.2670\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.5057 - acc: 0.3663Epoch 00001: saving model to weights\\LSTM_17_.01-0.367-3.506-0.291-4.249.h5\n",
      "9000/9000 [==============================] - 43s - loss: 3.5060 - acc: 0.3666 - val_loss: 4.2487 - val_acc: 0.2910\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.7343 - acc: 0.4761Epoch 00002: saving model to weights\\LSTM_17_.02-0.477-2.731-0.290-4.309.h5\n",
      "9000/9000 [==============================] - 41s - loss: 2.7311 - acc: 0.4769 - val_loss: 4.3094 - val_acc: 0.2900\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.9087 - acc: 0.2142Epoch 00000: saving model to weights\\LSTM_17_.00-0.214-4.907-0.187-4.874.h5\n",
      "9000/9000 [==============================] - 42s - loss: 4.9074 - acc: 0.2140 - val_loss: 4.8740 - val_acc: 0.1870\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.8681 - acc: 0.3182Epoch 00001: saving model to weights\\LSTM_17_.01-0.318-3.866-0.213-4.750.h5\n",
      "9000/9000 [==============================] - 43s - loss: 3.8662 - acc: 0.3179 - val_loss: 4.7503 - val_acc: 0.2130\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.0309 - acc: 0.4247Epoch 00002: saving model to weights\\LSTM_17_.02-0.425-3.031-0.217-4.754.h5\n",
      "9000/9000 [==============================] - 44s - loss: 3.0312 - acc: 0.4248 - val_loss: 4.7540 - val_acc: 0.2170\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.7559 - acc: 0.2265Epoch 00000: saving model to weights\\LSTM_17_.00-0.227-4.754-0.245-4.574.h5\n",
      "9000/9000 [==============================] - 41s - loss: 4.7540 - acc: 0.2272 - val_loss: 4.5740 - val_acc: 0.2450\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.8001 - acc: 0.3261Epoch 00001: saving model to weights\\LSTM_17_.01-0.326-3.800-0.255-4.411.h5\n",
      "9000/9000 [==============================] - 40s - loss: 3.7999 - acc: 0.3262 - val_loss: 4.4113 - val_acc: 0.2550\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.9868 - acc: 0.4323Epoch 00002: saving model to weights\\LSTM_17_.02-0.432-2.985-0.260-4.498.h5\n",
      "9000/9000 [==============================] - 41s - loss: 2.9850 - acc: 0.4324 - val_loss: 4.4979 - val_acc: 0.2600\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.1044 - acc: 0.2769Epoch 00000: saving model to weights\\LSTM_17_.00-0.277-4.109-0.302-3.949.h5\n",
      "9000/9000 [==============================] - 41s - loss: 4.1088 - acc: 0.2769 - val_loss: 3.9490 - val_acc: 0.3020\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.2161 - acc: 0.3927Epoch 00001: saving model to weights\\LSTM_17_.01-0.393-3.215-0.330-3.858.h5\n",
      "9000/9000 [==============================] - 39s - loss: 3.2150 - acc: 0.3930 - val_loss: 3.8580 - val_acc: 0.3300\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.5129 - acc: 0.4972Epoch 00002: saving model to weights\\LSTM_17_.02-0.498-2.514-0.323-3.908.h5\n",
      "9000/9000 [==============================] - 39s - loss: 2.5138 - acc: 0.4978 - val_loss: 3.9085 - val_acc: 0.3230\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.3125 - acc: 0.2606Epoch 00000: saving model to weights\\LSTM_17_.00-0.261-4.310-0.270-4.150.h5\n",
      "9000/9000 [==============================] - 43s - loss: 4.3099 - acc: 0.2610 - val_loss: 4.1498 - val_acc: 0.2700\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.3434 - acc: 0.3787Epoch 00001: saving model to weights\\LSTM_17_.01-0.379-3.345-0.315-4.044.h5\n",
      "9000/9000 [==============================] - 42s - loss: 3.3446 - acc: 0.3786 - val_loss: 4.0441 - val_acc: 0.3150\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.6026 - acc: 0.4881Epoch 00002: saving model to weights\\LSTM_17_.02-0.488-2.604-0.296-4.083.h5\n",
      "9000/9000 [==============================] - 42s - loss: 2.6036 - acc: 0.4879 - val_loss: 4.0826 - val_acc: 0.2960\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.5817 - acc: 0.2441Epoch 00000: saving model to weights\\LSTM_17_.00-0.244-4.581-0.270-4.311.h5\n",
      "9000/9000 [==============================] - 41s - loss: 4.5810 - acc: 0.2439 - val_loss: 4.3112 - val_acc: 0.2700\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.6233 - acc: 0.3637Epoch 00001: saving model to weights\\LSTM_17_.01-0.364-3.623-0.290-4.267.h5\n",
      "9000/9000 [==============================] - 41s - loss: 3.6226 - acc: 0.3640 - val_loss: 4.2673 - val_acc: 0.2900\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.8646 - acc: 0.4775Epoch 00002: saving model to weights\\LSTM_17_.02-0.477-2.867-0.291-4.290.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 42s - loss: 2.8665 - acc: 0.4769 - val_loss: 4.2901 - val_acc: 0.2910\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.4632 - acc: 0.2587Epoch 00000: saving model to weights\\LSTM_17_.00-0.258-4.464-0.289-4.207.h5\n",
      "9000/9000 [==============================] - 42s - loss: 4.4642 - acc: 0.2584 - val_loss: 4.2073 - val_acc: 0.2890\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.5284 - acc: 0.3763Epoch 00001: saving model to weights\\LSTM_17_.01-0.377-3.525-0.295-4.131.h5\n",
      "9000/9000 [==============================] - 43s - loss: 3.5255 - acc: 0.3767 - val_loss: 4.1308 - val_acc: 0.2950\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.7729 - acc: 0.4879Epoch 00002: saving model to weights\\LSTM_17_.02-0.488-2.772-0.279-4.225.h5\n",
      "9000/9000 [==============================] - 44s - loss: 2.7723 - acc: 0.4876 - val_loss: 4.2251 - val_acc: 0.2790\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.9700 - acc: 0.2347Epoch 00000: saving model to weights\\LSTM_17_.00-0.235-4.969-0.233-4.559.h5\n",
      "9000/9000 [==============================] - 41s - loss: 4.9689 - acc: 0.2347 - val_loss: 4.5595 - val_acc: 0.2330\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.7299 - acc: 0.3496Epoch 00001: saving model to weights\\LSTM_17_.01-0.350-3.728-0.260-4.376.h5\n",
      "9000/9000 [==============================] - 45s - loss: 3.7283 - acc: 0.3499 - val_loss: 4.3755 - val_acc: 0.2600\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.9025 - acc: 0.4606Epoch 00002: saving model to weights\\LSTM_17_.02-0.461-2.902-0.280-4.301.h5\n",
      "9000/9000 [==============================] - 45s - loss: 2.9020 - acc: 0.4607 - val_loss: 4.3009 - val_acc: 0.2800\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.6816 - acc: 0.2452Epoch 00000: saving model to weights\\LSTM_17_.00-0.245-4.680-0.289-4.486.h5\n",
      "9000/9000 [==============================] - 46s - loss: 4.6804 - acc: 0.2450 - val_loss: 4.4856 - val_acc: 0.2890\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.6213 - acc: 0.3725Epoch 00001: saving model to weights\\LSTM_17_.01-0.373-3.625-0.301-4.366.h5\n",
      "9000/9000 [==============================] - 43s - loss: 3.6247 - acc: 0.3726 - val_loss: 4.3660 - val_acc: 0.3010\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.8406 - acc: 0.4975Epoch 00002: saving model to weights\\LSTM_17_.02-0.498-2.840-0.312-4.379.h5\n",
      "9000/9000 [==============================] - 43s - loss: 2.8401 - acc: 0.4978 - val_loss: 4.3791 - val_acc: 0.3120\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 5.2962 - acc: 0.1936Epoch 00000: saving model to weights\\LSTM_17_.00-0.193-5.295-0.233-4.955.h5\n",
      "9000/9000 [==============================] - 41s - loss: 5.2946 - acc: 0.1933 - val_loss: 4.9551 - val_acc: 0.2330\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.2118 - acc: 0.3097Epoch 00001: saving model to weights\\LSTM_17_.01-0.310-4.210-0.253-4.796.h5\n",
      "9000/9000 [==============================] - 41s - loss: 4.2101 - acc: 0.3096 - val_loss: 4.7964 - val_acc: 0.2530\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.3606 - acc: 0.4217Epoch 00002: saving model to weights\\LSTM_17_.02-0.422-3.363-0.258-4.789.h5\n",
      "9000/9000 [==============================] - 39s - loss: 3.3627 - acc: 0.4218 - val_loss: 4.7895 - val_acc: 0.2580\n",
      "Building array.\n",
      "Training.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 4.5615 - acc: 0.2564Epoch 00000: saving model to weights\\LSTM_17_.00-0.257-4.557-0.284-4.444.h5\n",
      "9000/9000 [==============================] - 40s - loss: 4.5569 - acc: 0.2571 - val_loss: 4.4440 - val_acc: 0.2840\n",
      "Epoch 2/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 3.6243 - acc: 0.3731Epoch 00001: saving model to weights\\LSTM_17_.01-0.374-3.626-0.314-4.339.h5\n",
      "9000/9000 [==============================] - 39s - loss: 3.6258 - acc: 0.3736 - val_loss: 4.3391 - val_acc: 0.3140\n",
      "Epoch 3/3\n",
      "8960/9000 [============================>.] - ETA: 0s - loss: 2.8932 - acc: 0.4815Epoch 00002: saving model to weights\\LSTM_17_.02-0.482-2.892-0.318-4.356.h5\n",
      "9000/9000 [==============================] - 39s - loss: 2.8916 - acc: 0.4817 - val_loss: 4.3562 - val_acc: 0.3180\n",
      "Building array.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-763d7d22481f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtraining_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4000000\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Building array.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_sequence_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_SAMPLES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTRIDE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Documents\\Work\\jarnn\\utils.py\u001b[0m in \u001b[0;36mbuild_sequence_array\u001b[1;34m(text, num_samples, labels, sequence_length, stride, verbose)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mcharacter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_start\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlabel_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Documents\\Work\\jarnn\\utils.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(character, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcharacter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(30): # 14 on second run (memento)\n",
    "    training_text = full_text[4000000+(i*1000000):]\n",
    "    print(\"Building array.\")\n",
    "    x, y = build_sequence_array(training_text, NUM_SAMPLES, labels, SEQUENCE_LENGTH, STRIDE, verbose=False)\n",
    "    x, y = sklearn.utils.shuffle(x, y, random_state=0)\n",
    "    print(\"Training.\")\n",
    "    model.fit(x, y, batch_size=256, epochs=3, callbacks=[get_save_callback(model_id)], validation_split=VAL_SPLIT_PERCENTAGE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
